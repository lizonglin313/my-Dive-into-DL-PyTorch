{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建Tensor\n",
    "在PyTorch中，`torch.Tensor`是存储和变换数据的主要工具。如果你之前用过NumPy，你会发现Tensor和NumPy的多维数组非常类似。然而，Tensor提供GPU计算和自动求梯度等更多功能，这些使Tensor更加适合深度学习。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.1837e-39, 1.0102e-38, 8.4490e-39],\n",
      "        [1.0102e-38, 9.0919e-39, 1.0102e-38],\n",
      "        [8.9082e-39, 8.9082e-39, 8.9082e-39],\n",
      "        [1.0194e-38, 9.1837e-39, 4.6837e-39],\n",
      "        [9.9184e-39, 9.0000e-39, 1.0561e-38]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7259, 0.7637, 0.5896],\n",
      "        [0.5844, 0.1504, 0.9950],\n",
      "        [0.1298, 0.5107, 0.5530],\n",
      "        [0.1773, 0.1390, 0.6530],\n",
      "        [0.8166, 0.3640, 0.8804]])\n"
     ]
    }
   ],
   "source": [
    "# 创建随机初始化的tensor\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# long型全0 Tensor\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.9000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# 直接根据数据创建\n",
    "x = torch.tensor([8.9, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.7157,  0.7138,  2.4869],\n",
      "        [ 1.8405, -0.6086, -1.1210],\n",
      "        [ 1.1452,  1.8947, -1.7320],\n",
      "        [-0.4556,  1.3090,  0.3424],\n",
      "        [ 0.1386, -0.6282, -0.4608]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 通过现有的Tensor创建 可以重用属性\n",
    "x = x.new_ones(5, 3, dtype=torch.float64)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)  # 指定新的类型\n",
    "print(x)\n",
    "\n",
    "# 获取tensor形状\n",
    "print(x.size())\n",
    "print(x.shape) # 注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 操作Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3498,  1.3994,  3.2339],\n",
      "        [ 2.4827, -0.3416, -0.4119],\n",
      "        [ 1.2784,  2.0313, -1.4079],\n",
      "        [-0.3478,  1.4029,  0.6472],\n",
      "        [ 0.7595, -0.1090,  0.4574]])\n",
      "tensor([[-0.3498,  1.3994,  3.2339],\n",
      "        [ 2.4827, -0.3416, -0.4119],\n",
      "        [ 1.2784,  2.0313, -1.4079],\n",
      "        [-0.3478,  1.4029,  0.6472],\n",
      "        [ 0.7595, -0.1090,  0.4574]])\n",
      "tensor([[-0.3498,  1.3994,  3.2339],\n",
      "        [ 2.4827, -0.3416, -0.4119],\n",
      "        [ 1.2784,  2.0313, -1.4079],\n",
      "        [-0.3478,  1.4029,  0.6472],\n",
      "        [ 0.7595, -0.1090,  0.4574]])\n",
      "tensor([[-0.3498,  1.3994,  3.2339],\n",
      "        [ 2.4827, -0.3416, -0.4119],\n",
      "        [ 1.2784,  2.0313, -1.4079],\n",
      "        [-0.3478,  1.4029,  0.6472],\n",
      "        [ 0.7595, -0.1090,  0.4574]])\n"
     ]
    }
   ],
   "source": [
    "# 不同的加法形式\n",
    "# 1\n",
    "y = torch.rand(5,3)\n",
    "print(x+y)\n",
    "\n",
    "# 2\n",
    "print(torch.add(x,y))\n",
    "\n",
    "# 3\n",
    "# 还可以执行运算的输出\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "# 4\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2843, 1.7138, 3.4869])\n",
      "tensor([0.2843, 1.7138, 3.4869])\n"
     ]
    }
   ],
   "source": [
    "y = x[0, :]\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0, :]) # 源tensor也被改了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改变形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(15)\n",
    "z = x.view(-1, 5)\n",
    "print(y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变)\n",
    "所以如果我们想返回一个真正新的副本（即不共享data内存）该怎么办呢？推荐先用clone创造一个副本然后再使用view。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7157,  0.7138,  2.4869],\n",
      "        [ 0.8405, -1.6086, -2.1210],\n",
      "        [ 0.1452,  0.8947, -2.7320],\n",
      "        [-1.4556,  0.3090, -0.6576],\n",
      "        [-0.8614, -1.6282, -1.4608]])\n",
      "tensor([ 0.2843,  1.7138,  3.4869,  1.8405, -0.6086, -1.1210,  1.1452,  1.8947,\n",
      "        -1.7320, -0.4556,  1.3090,  0.3424,  0.1386, -0.6282, -0.4608])\n"
     ]
    }
   ],
   "source": [
    "x_cp = x.clone().view(15)   # 先 clone 再改形状\n",
    "x -= 1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用clone还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6411])\n",
      "0.6411486268043518\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item()) # 另外一个常用的函数就是item(), 它可以将一个标量Tensor转换成一个Python number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性代数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch中的Tensor支持超过一百种操作，包括转置、索引、切片、数学运算、线性代数、随机数等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个形状不同的Tensor按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个Tensor形状相同后再按元素运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1,2)\n",
    "print(x)\n",
    "y = torch.arange(1,4).view(3,1)\n",
    "print(y)\n",
    "print(x+y)\n",
    "# x第2、3行复制了第一行\n",
    "# y第2列复制第一列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行时内存\n",
    "索引操作是不会开辟新内存的，而像`y = x + y`这样的运算是会新开内存的，然后将`y`指向新内存。为了演示这一点，我们可以使用Python自带的id函数：如果两个实例的ID一致，那么它们所对应的内存地址相同；反之则不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y = y + x\n",
    "print(id(y) == id_before) # False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想指定结果到原来的`y`的内存，我们可以使用前面介绍的索引来进行替换操作。在下面的例子中，我们把`x + y`的结果通过`[:]`写进`y`对应的内存中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "y[:] = y + x\n",
    "print(id(y) == id_before) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以使用运算符全名函数中的`out`参数或者自加运算符`+=`(也即`add_()`)达到上述效果."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "id_before = id(y)\n",
    "torch.add(x, y, out=y) # y += x, y.add_(x)\n",
    "print(id(y) == id_before) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于view():虽然view返回的Tensor与源Tensor是共享data的，但是依然是一个新的Tensor（因为Tensor除了包含data外还有一些其他属性），二者id（内存地址）并不一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor和Numpy相互转换\n",
    "\n",
    "注意，用`numpy()`和`from_numpy()`将`Tensor`和`NumPy`中的数组相互转换。但是需要注意的一点是： 这两个函数所产生的`Tensor`和`NumPy`中的数组共享相同的内存（所以他们之间的转换很快），改变其中一个时另一个也会改变！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n",
      "tensor([4., 4., 4., 4., 4.]) [4. 4. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "# tensor 转 numpy\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, b)\n",
    "\n",
    "a+=1\n",
    "print(a,b)\n",
    "b+=2\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy转Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a, b)\n",
    "\n",
    "a += 1\n",
    "print(a, b)\n",
    "b += 1\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有在CPU上的Tensor（除了CharTensor）都支持与NumPy数组相互转换。\n",
    "\n",
    "此外上面提到还有一个常用的方法就是直接用torch.tensor()将NumPy数组转换成Tensor，需要注意的是该方法总是会进行数据拷贝，**返回的Tensor和原来的数据不再共享内存**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor(a)\n",
    "a += 1\n",
    "print(a, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([2, 3], device='cuda:0')\n",
      "tensor([2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 使用 to() 将 Tensor 在 CPU 和 GPU之间的移动\n",
    "# 需要有硬件支持\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # GPU\n",
    "    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\n",
    "    x = x.to(device)                       # 等价于 .to(\"cuda\")\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75b6c9faefd3632622134dd0aa73546de62307e6a2df9b20f52f8cd2c4d749b9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
