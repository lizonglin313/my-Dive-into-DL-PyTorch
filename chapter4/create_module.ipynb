{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造模型\n",
    "### 继承Module构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    # 声明带有模型参数的层 这里是两个全连接层\n",
    "    def __init__(self, **kwargs):   # 重写init方法\n",
    "        # 调用MLP父类Module的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "        # 参数，如“模型参数的访问、初始化和共享”一节将介绍的模型参数params\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(784, 256)   # 添加隐藏层\n",
    "        self.act = nn.ReLU()                # 激活函数\n",
    "        self.output = nn.Linear(256, 10)    # 输出层\n",
    "\n",
    "    # 重写前向计算\n",
    "    def forward(self, x):\n",
    "        a = self.act(self.hidden(x))\n",
    "        return self.output(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (act): ReLU()\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0291,  0.1236,  0.1575, -0.0775,  0.1388, -0.0207,  0.0736,  0.0382,\n",
       "          0.0693, -0.1443],\n",
       "        [ 0.0658,  0.1074,  0.1143,  0.0444,  0.0876, -0.1488, -0.0525,  0.0597,\n",
       "          0.1048, -0.1135]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2, 784)\n",
    "net = MLP() \n",
    "print(net)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module子类\n",
    "#### Sequentital类\n",
    "下面我们实现一个与Sequential类有相同功能的MySequential类。这或许可以帮助读者更加清晰地理解Sequential类的工作机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    from collections import OrderedDict\n",
    "    def __init__(self, *args):\n",
    "        super(MySequential, self).__init__()\n",
    "        # 如果传入OrderedDict\n",
    "        if len(args)==1 and isinstance(args[0], OrderedDict):\n",
    "            for key, module in args[0].items():\n",
    "                # add_module方法会将module添加进self._modules(一个OrderedDict)\n",
    "                self.add_module(key, module)\n",
    "        else:   # 如果传入的是一些module\n",
    "            for idx, module in enumerate(args):\n",
    "                self.add_module(str(idx), module)\n",
    "    def forward(self, input):\n",
    "        # self._modules返回一个 OrderedDict，保证会按照成员添加时的顺序遍历成员\n",
    "        for module in self._modules.values():\n",
    "            input = module(input)\n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们用MySequential类来实现前面描述的MLP类，并使用随机初始化的模型做一次前向计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0142,  0.0628, -0.2660,  0.2819, -0.0818, -0.0891, -0.1679,  0.0602,\n",
       "          0.3058,  0.1863],\n",
       "        [-0.0190, -0.0413, -0.1987,  0.1918,  0.0100, -0.1111, -0.2944,  0.1756,\n",
       "          0.2174,  0.1130]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10),\n",
    ")\n",
    "print(net)\n",
    "net(X)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69f913797b69e5e1b7e33afee28d9d42e281516b707cecd11e88f5184cf6c73e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
